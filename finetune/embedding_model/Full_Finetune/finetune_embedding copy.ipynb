{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8fb99b",
   "metadata": {},
   "source": [
    "1. Create & Prepare embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a1801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HocTap\\ChatBot\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 197379\n",
      "After: 159501\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    " \n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset('csv', data_files='../dataset/QA_data.csv', split=\"train\")\n",
    "\n",
    "\n",
    "# Shuffle trước để chọn ngẫu nhiên\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Lấy 1/100 số dòng\n",
    "# dataset = dataset.select(range(len(dataset) // 100))\n",
    "\n",
    "\n",
    "print(\"Before:\", len(dataset))\n",
    "dataset = dataset.filter(lambda x: x[\"Answer\"])\n",
    "print(\"After:\", len(dataset))\n",
    "# rename columns\n",
    "dataset = dataset.rename_column(\"Question\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"Answer\", \"positive\")\n",
    " \n",
    "# Add an id column to the dataset\n",
    "dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
    " \n",
    "# split dataset into a 10% test set\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    " \n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_pandas().to_json(\"train_dataset.json\", orient=\"records\", lines=True, force_ascii=False)\n",
    "dataset[\"test\"].to_pandas().to_json(\"test_dataset.json\", orient=\"records\", lines=True, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efac7b",
   "metadata": {},
   "source": [
    "2. Create baseline and evaluate pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785a78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 15951 examples [00:00, 361251.10 examples/s]\n",
      "Generating train split: 143550 examples [00:00, 603611.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    " \n",
    "# load test dataset\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    " \n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)\n",
    " \n",
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ace00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "model_id = \"bkai-foundation-models/vietnamese-bi-encoder\"  # Hugging Face model ID\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64] # Important: large to small\n",
    " \n",
    "# Load a model\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    " \n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c48386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_accuracy@1 0.23227383863080683\n",
      "dim_768_cosine_accuracy@3 0.35847282302050026\n",
      "dim_768_cosine_accuracy@5 0.4165256096796439\n",
      "dim_768_cosine_accuracy@10 0.4767726161369193\n",
      "dim_768_cosine_precision@1 0.23227383863080683\n",
      "dim_768_cosine_precision@3 0.11949094100683343\n",
      "dim_768_cosine_precision@5 0.08330512193592877\n",
      "dim_768_cosine_precision@10 0.04767726161369193\n",
      "dim_768_cosine_recall@1 0.23227383863080683\n",
      "dim_768_cosine_recall@3 0.35847282302050026\n",
      "dim_768_cosine_recall@5 0.4165256096796439\n",
      "dim_768_cosine_recall@10 0.4767726161369193\n",
      "dim_768_cosine_ndcg@10 0.34935886247371617\n",
      "dim_768_cosine_mrr@10 0.309086856275119\n",
      "dim_768_cosine_map@100 0.31452434828195525\n",
      "dim_512_cosine_accuracy@1 0.23108269074039245\n",
      "dim_512_cosine_accuracy@3 0.35571437527427746\n",
      "dim_512_cosine_accuracy@5 0.4132656259795624\n",
      "dim_512_cosine_accuracy@10 0.4730110964829791\n",
      "dim_512_cosine_precision@1 0.23108269074039245\n",
      "dim_512_cosine_precision@3 0.11857145842475914\n",
      "dim_512_cosine_precision@5 0.08265312519591249\n",
      "dim_512_cosine_precision@10 0.04730110964829791\n",
      "dim_512_cosine_recall@1 0.23108269074039245\n",
      "dim_512_cosine_recall@3 0.35571437527427746\n",
      "dim_512_cosine_recall@5 0.4132656259795624\n",
      "dim_512_cosine_recall@10 0.4730110964829791\n",
      "dim_512_cosine_ndcg@10 0.346886104521598\n",
      "dim_512_cosine_mrr@10 0.3070306086198502\n",
      "dim_512_cosine_map@100 0.31252857667321415\n",
      "dim_256_cosine_accuracy@1 0.2208638956805216\n",
      "dim_256_cosine_accuracy@3 0.34330136041627485\n",
      "dim_256_cosine_accuracy@5 0.39640147953106386\n",
      "dim_256_cosine_accuracy@10 0.4547677261613692\n",
      "dim_256_cosine_precision@1 0.2208638956805216\n",
      "dim_256_cosine_precision@3 0.11443378680542494\n",
      "dim_256_cosine_precision@5 0.07928029590621277\n",
      "dim_256_cosine_precision@10 0.04547677261613692\n",
      "dim_256_cosine_recall@1 0.2208638956805216\n",
      "dim_256_cosine_recall@3 0.34330136041627485\n",
      "dim_256_cosine_recall@5 0.39640147953106386\n",
      "dim_256_cosine_recall@10 0.4547677261613692\n",
      "dim_256_cosine_ndcg@10 0.3328258369624199\n",
      "dim_256_cosine_mrr@10 0.29430060114656686\n",
      "dim_256_cosine_map@100 0.29978209729394056\n",
      "dim_128_cosine_accuracy@1 0.1947840260798696\n",
      "dim_128_cosine_accuracy@3 0.30819384364616637\n",
      "dim_128_cosine_accuracy@5 0.3562159112281362\n",
      "dim_128_cosine_accuracy@10 0.4103191022506426\n",
      "dim_128_cosine_precision@1 0.1947840260798696\n",
      "dim_128_cosine_precision@3 0.10273128121538878\n",
      "dim_128_cosine_precision@5 0.07124318224562723\n",
      "dim_128_cosine_precision@10 0.04103191022506425\n",
      "dim_128_cosine_recall@1 0.1947840260798696\n",
      "dim_128_cosine_recall@3 0.30819384364616637\n",
      "dim_128_cosine_recall@5 0.3562159112281362\n",
      "dim_128_cosine_recall@10 0.4103191022506426\n",
      "dim_128_cosine_ndcg@10 0.2981043346415172\n",
      "dim_128_cosine_mrr@10 0.26264606985878447\n",
      "dim_128_cosine_map@100 0.2679689854247028\n",
      "dim_64_cosine_accuracy@1 0.15641652560967964\n",
      "dim_64_cosine_accuracy@3 0.24844837314274967\n",
      "dim_64_cosine_accuracy@5 0.28769356153219233\n",
      "dim_64_cosine_accuracy@10 0.3356529371199298\n",
      "dim_64_cosine_precision@1 0.15641652560967964\n",
      "dim_64_cosine_precision@3 0.08281612438091655\n",
      "dim_64_cosine_precision@5 0.057538712306438464\n",
      "dim_64_cosine_precision@10 0.033565293711992975\n",
      "dim_64_cosine_recall@1 0.15641652560967964\n",
      "dim_64_cosine_recall@3 0.24844837314274967\n",
      "dim_64_cosine_recall@5 0.28769356153219233\n",
      "dim_64_cosine_recall@10 0.3356529371199298\n",
      "dim_64_cosine_ndcg@10 0.24153984099321327\n",
      "dim_64_cosine_mrr@10 0.21191361839283684\n",
      "dim_64_cosine_map@100 0.21666215595031468\n",
      "sequential_score 0.24153984099321327\n",
      "=======================\n",
      "dim_768_cosine_ndcg@10: 0.34935886247371617\n",
      "dim_512_cosine_ndcg@10: 0.346886104521598\n",
      "dim_256_cosine_ndcg@10: 0.3328258369624199\n",
      "dim_128_cosine_ndcg@10: 0.2981043346415172\n",
      "dim_64_cosine_ndcg@10: 0.24153984099321327\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = evaluator(model)\n",
    "for k,v in results.items():\n",
    "    print(k, v)\n",
    "\n",
    "print(\"=======================\")\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1f694",
   "metadata": {},
   "source": [
    "3. Define loss function with Matryoshka Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a9ee62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['anchor', 'Context', 'positive', 'Answer_Start', 'Answer_End', 'id'],\n",
       "    num_rows: 143550\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData, SentenceTransformer\n",
    " \n",
    "# Hugging Face model ID: https://huggingface.co/BAAI/bge-base-en-v1.5\n",
    "model_id = \"bkai-foundation-models/vietnamese-bi-encoder\"\n",
    " \n",
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    model_id,\n",
    "    model_kwargs={\"attn_implementation\": \"sdpa\"},\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"BGE base Financial Matryoshka\",\n",
    "    ),\n",
    ")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96822aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'Tôi bị nhiễm covid, đã hoàn thành điều trị, về cách ly tại nhà dc 4 ngày, giờ ko ho ko sốt, nhưng cổ có mắc đàm, vòm họng đỏ, hơi rát, vì có bị viêm amidan mãn tính, vậy cho e hỏi e có thể uống thuốc gì dc ạ, e còn thuốc điều trị amidan có uống dc ko',\n",
       " 'Context': 'Chào chị Dạ chào bác sỹ Chị đặt giúp em một lịch tư vấn online miễn phí. Em gọi điện hỏi thêm triệu chứng và tư vấn cụ thể cho chị nhé Chị ấn vào ảnh đại diện của em, ấn tư vấn trực tuyến, ấn xác nhận và đặt lịch ạ Cảm ơn chị',\n",
       " 'positive': 'Chào chị Dạ chào bác sỹ Chị đặt giúp em một lịch tư vấn online miễn phí. Em gọi điện hỏi thêm triệu chứng và tư vấn cụ thể cho chị nhé Chị ấn vào ảnh đại diện của em, ấn tư vấn trực tuyến, ấn xác nhận và đặt lịch ạ Cảm ơn chị',\n",
       " 'Answer_Start': 0,\n",
       " 'Answer_End': 225,\n",
       " 'id': 88434}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04face0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    " \n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abdfb8",
   "metadata": {},
   "source": [
    "4. Fine-tune embedding model with SentenceTransformersTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c225058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    " \n",
    "# load train dataset again\n",
    " \n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"sample\", # output directory and hugging face model ID\n",
    "    num_train_epochs=10,                         # number of epochs\n",
    "    per_device_train_batch_size=16,             # train batch size\n",
    "    gradient_accumulation_steps=8,             # for a global batch size of 512\n",
    "    per_device_eval_batch_size=8,    \n",
    "    #gradient_checkpointing=True,\n",
    "    warmup_ratio=0.1,                           # warmup ratio\n",
    "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "    # tf32=True,                                  # use tf32 precision\n",
    "    bf16=True,                                  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",  \n",
    "    # save_steps = 500,\n",
    "    logging_steps=10,                           # log every 10 steps\n",
    "    save_total_limit=3,                         # save only the last 3 models\n",
    "    load_best_model_at_end=True,                # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    "    report_to = \"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c448529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    " \n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model, # bg-base-en-v1\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"anchor\", \"positive\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a3d8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11210' max='11210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11210/11210 31:38:11, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 768 Cosine Accuracy@1</th>\n",
       "      <th>Dim 768 Cosine Accuracy@3</th>\n",
       "      <th>Dim 768 Cosine Accuracy@5</th>\n",
       "      <th>Dim 768 Cosine Accuracy@10</th>\n",
       "      <th>Dim 768 Cosine Precision@1</th>\n",
       "      <th>Dim 768 Cosine Precision@3</th>\n",
       "      <th>Dim 768 Cosine Precision@5</th>\n",
       "      <th>Dim 768 Cosine Precision@10</th>\n",
       "      <th>Dim 768 Cosine Recall@1</th>\n",
       "      <th>Dim 768 Cosine Recall@3</th>\n",
       "      <th>Dim 768 Cosine Recall@5</th>\n",
       "      <th>Dim 768 Cosine Recall@10</th>\n",
       "      <th>Dim 768 Cosine Ndcg@10</th>\n",
       "      <th>Dim 768 Cosine Mrr@10</th>\n",
       "      <th>Dim 768 Cosine Map@100</th>\n",
       "      <th>Dim 512 Cosine Accuracy@1</th>\n",
       "      <th>Dim 512 Cosine Accuracy@3</th>\n",
       "      <th>Dim 512 Cosine Accuracy@5</th>\n",
       "      <th>Dim 512 Cosine Accuracy@10</th>\n",
       "      <th>Dim 512 Cosine Precision@1</th>\n",
       "      <th>Dim 512 Cosine Precision@3</th>\n",
       "      <th>Dim 512 Cosine Precision@5</th>\n",
       "      <th>Dim 512 Cosine Precision@10</th>\n",
       "      <th>Dim 512 Cosine Recall@1</th>\n",
       "      <th>Dim 512 Cosine Recall@3</th>\n",
       "      <th>Dim 512 Cosine Recall@5</th>\n",
       "      <th>Dim 512 Cosine Recall@10</th>\n",
       "      <th>Dim 512 Cosine Ndcg@10</th>\n",
       "      <th>Dim 512 Cosine Mrr@10</th>\n",
       "      <th>Dim 512 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Dim 128 Cosine Accuracy@1</th>\n",
       "      <th>Dim 128 Cosine Accuracy@3</th>\n",
       "      <th>Dim 128 Cosine Accuracy@5</th>\n",
       "      <th>Dim 128 Cosine Accuracy@10</th>\n",
       "      <th>Dim 128 Cosine Precision@1</th>\n",
       "      <th>Dim 128 Cosine Precision@3</th>\n",
       "      <th>Dim 128 Cosine Precision@5</th>\n",
       "      <th>Dim 128 Cosine Precision@10</th>\n",
       "      <th>Dim 128 Cosine Recall@1</th>\n",
       "      <th>Dim 128 Cosine Recall@3</th>\n",
       "      <th>Dim 128 Cosine Recall@5</th>\n",
       "      <th>Dim 128 Cosine Recall@10</th>\n",
       "      <th>Dim 128 Cosine Ndcg@10</th>\n",
       "      <th>Dim 128 Cosine Mrr@10</th>\n",
       "      <th>Dim 128 Cosine Map@100</th>\n",
       "      <th>Dim 64 Cosine Accuracy@1</th>\n",
       "      <th>Dim 64 Cosine Accuracy@3</th>\n",
       "      <th>Dim 64 Cosine Accuracy@5</th>\n",
       "      <th>Dim 64 Cosine Accuracy@10</th>\n",
       "      <th>Dim 64 Cosine Precision@1</th>\n",
       "      <th>Dim 64 Cosine Precision@3</th>\n",
       "      <th>Dim 64 Cosine Precision@5</th>\n",
       "      <th>Dim 64 Cosine Precision@10</th>\n",
       "      <th>Dim 64 Cosine Recall@1</th>\n",
       "      <th>Dim 64 Cosine Recall@3</th>\n",
       "      <th>Dim 64 Cosine Recall@5</th>\n",
       "      <th>Dim 64 Cosine Recall@10</th>\n",
       "      <th>Dim 64 Cosine Ndcg@10</th>\n",
       "      <th>Dim 64 Cosine Mrr@10</th>\n",
       "      <th>Dim 64 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.883900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372265</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.571375</td>\n",
       "      <td>0.620463</td>\n",
       "      <td>0.372265</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.114275</td>\n",
       "      <td>0.062046</td>\n",
       "      <td>0.372265</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.571375</td>\n",
       "      <td>0.620463</td>\n",
       "      <td>0.496825</td>\n",
       "      <td>0.457113</td>\n",
       "      <td>0.462092</td>\n",
       "      <td>0.368629</td>\n",
       "      <td>0.523729</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.618645</td>\n",
       "      <td>0.368629</td>\n",
       "      <td>0.174576</td>\n",
       "      <td>0.114288</td>\n",
       "      <td>0.061864</td>\n",
       "      <td>0.368629</td>\n",
       "      <td>0.523729</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.618645</td>\n",
       "      <td>0.494357</td>\n",
       "      <td>0.454411</td>\n",
       "      <td>0.459396</td>\n",
       "      <td>0.363676</td>\n",
       "      <td>0.516958</td>\n",
       "      <td>0.565043</td>\n",
       "      <td>0.613817</td>\n",
       "      <td>0.363676</td>\n",
       "      <td>0.172319</td>\n",
       "      <td>0.113009</td>\n",
       "      <td>0.061382</td>\n",
       "      <td>0.363676</td>\n",
       "      <td>0.516958</td>\n",
       "      <td>0.565043</td>\n",
       "      <td>0.613817</td>\n",
       "      <td>0.489135</td>\n",
       "      <td>0.449090</td>\n",
       "      <td>0.454043</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.503354</td>\n",
       "      <td>0.552567</td>\n",
       "      <td>0.603536</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.167785</td>\n",
       "      <td>0.110513</td>\n",
       "      <td>0.060354</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.503354</td>\n",
       "      <td>0.552567</td>\n",
       "      <td>0.603536</td>\n",
       "      <td>0.477686</td>\n",
       "      <td>0.437332</td>\n",
       "      <td>0.442267</td>\n",
       "      <td>0.324933</td>\n",
       "      <td>0.471569</td>\n",
       "      <td>0.519529</td>\n",
       "      <td>0.571626</td>\n",
       "      <td>0.324933</td>\n",
       "      <td>0.157190</td>\n",
       "      <td>0.103906</td>\n",
       "      <td>0.057163</td>\n",
       "      <td>0.324933</td>\n",
       "      <td>0.471569</td>\n",
       "      <td>0.519529</td>\n",
       "      <td>0.571626</td>\n",
       "      <td>0.447395</td>\n",
       "      <td>0.407659</td>\n",
       "      <td>0.412994</td>\n",
       "      <td>0.447395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.087900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.388878</td>\n",
       "      <td>0.540593</td>\n",
       "      <td>0.587926</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.388878</td>\n",
       "      <td>0.180198</td>\n",
       "      <td>0.117585</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>0.388878</td>\n",
       "      <td>0.540593</td>\n",
       "      <td>0.587926</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>0.513486</td>\n",
       "      <td>0.473720</td>\n",
       "      <td>0.478893</td>\n",
       "      <td>0.387938</td>\n",
       "      <td>0.536518</td>\n",
       "      <td>0.586609</td>\n",
       "      <td>0.634694</td>\n",
       "      <td>0.387938</td>\n",
       "      <td>0.178839</td>\n",
       "      <td>0.117322</td>\n",
       "      <td>0.063469</td>\n",
       "      <td>0.387938</td>\n",
       "      <td>0.536518</td>\n",
       "      <td>0.586609</td>\n",
       "      <td>0.634694</td>\n",
       "      <td>0.511661</td>\n",
       "      <td>0.472181</td>\n",
       "      <td>0.477426</td>\n",
       "      <td>0.382421</td>\n",
       "      <td>0.534136</td>\n",
       "      <td>0.579337</td>\n",
       "      <td>0.627359</td>\n",
       "      <td>0.382421</td>\n",
       "      <td>0.178045</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.382421</td>\n",
       "      <td>0.534136</td>\n",
       "      <td>0.579337</td>\n",
       "      <td>0.627359</td>\n",
       "      <td>0.505731</td>\n",
       "      <td>0.466632</td>\n",
       "      <td>0.472020</td>\n",
       "      <td>0.371325</td>\n",
       "      <td>0.521723</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>0.617203</td>\n",
       "      <td>0.371325</td>\n",
       "      <td>0.173908</td>\n",
       "      <td>0.113849</td>\n",
       "      <td>0.061720</td>\n",
       "      <td>0.371325</td>\n",
       "      <td>0.521723</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>0.617203</td>\n",
       "      <td>0.494705</td>\n",
       "      <td>0.455363</td>\n",
       "      <td>0.460718</td>\n",
       "      <td>0.346123</td>\n",
       "      <td>0.492822</td>\n",
       "      <td>0.539966</td>\n",
       "      <td>0.590935</td>\n",
       "      <td>0.346123</td>\n",
       "      <td>0.164274</td>\n",
       "      <td>0.107993</td>\n",
       "      <td>0.059093</td>\n",
       "      <td>0.346123</td>\n",
       "      <td>0.492822</td>\n",
       "      <td>0.539966</td>\n",
       "      <td>0.590935</td>\n",
       "      <td>0.468365</td>\n",
       "      <td>0.429123</td>\n",
       "      <td>0.434847</td>\n",
       "      <td>0.468365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.371800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398157</td>\n",
       "      <td>0.547991</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.398157</td>\n",
       "      <td>0.182664</td>\n",
       "      <td>0.118927</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>0.398157</td>\n",
       "      <td>0.547991</td>\n",
       "      <td>0.594634</td>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.521257</td>\n",
       "      <td>0.482317</td>\n",
       "      <td>0.487589</td>\n",
       "      <td>0.395148</td>\n",
       "      <td>0.546047</td>\n",
       "      <td>0.591938</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.395148</td>\n",
       "      <td>0.182016</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.064090</td>\n",
       "      <td>0.395148</td>\n",
       "      <td>0.546047</td>\n",
       "      <td>0.591938</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.519017</td>\n",
       "      <td>0.479852</td>\n",
       "      <td>0.485138</td>\n",
       "      <td>0.391574</td>\n",
       "      <td>0.541283</td>\n",
       "      <td>0.586860</td>\n",
       "      <td>0.634945</td>\n",
       "      <td>0.391574</td>\n",
       "      <td>0.180428</td>\n",
       "      <td>0.117372</td>\n",
       "      <td>0.063494</td>\n",
       "      <td>0.391574</td>\n",
       "      <td>0.541283</td>\n",
       "      <td>0.586860</td>\n",
       "      <td>0.634945</td>\n",
       "      <td>0.514033</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>0.480522</td>\n",
       "      <td>0.379412</td>\n",
       "      <td>0.532130</td>\n",
       "      <td>0.576704</td>\n",
       "      <td>0.626105</td>\n",
       "      <td>0.379412</td>\n",
       "      <td>0.177377</td>\n",
       "      <td>0.115341</td>\n",
       "      <td>0.062610</td>\n",
       "      <td>0.379412</td>\n",
       "      <td>0.532130</td>\n",
       "      <td>0.576704</td>\n",
       "      <td>0.626105</td>\n",
       "      <td>0.503916</td>\n",
       "      <td>0.464651</td>\n",
       "      <td>0.469884</td>\n",
       "      <td>0.363175</td>\n",
       "      <td>0.507429</td>\n",
       "      <td>0.554385</td>\n",
       "      <td>0.601655</td>\n",
       "      <td>0.363175</td>\n",
       "      <td>0.169143</td>\n",
       "      <td>0.110877</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.363175</td>\n",
       "      <td>0.507429</td>\n",
       "      <td>0.554385</td>\n",
       "      <td>0.601655</td>\n",
       "      <td>0.482537</td>\n",
       "      <td>0.444313</td>\n",
       "      <td>0.449938</td>\n",
       "      <td>0.482537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.053500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.406620</td>\n",
       "      <td>0.557896</td>\n",
       "      <td>0.601780</td>\n",
       "      <td>0.648047</td>\n",
       "      <td>0.406620</td>\n",
       "      <td>0.185965</td>\n",
       "      <td>0.120356</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.406620</td>\n",
       "      <td>0.557896</td>\n",
       "      <td>0.601780</td>\n",
       "      <td>0.648047</td>\n",
       "      <td>0.528776</td>\n",
       "      <td>0.490377</td>\n",
       "      <td>0.495827</td>\n",
       "      <td>0.402295</td>\n",
       "      <td>0.555326</td>\n",
       "      <td>0.600589</td>\n",
       "      <td>0.646919</td>\n",
       "      <td>0.402295</td>\n",
       "      <td>0.185109</td>\n",
       "      <td>0.120118</td>\n",
       "      <td>0.064692</td>\n",
       "      <td>0.402295</td>\n",
       "      <td>0.555326</td>\n",
       "      <td>0.600589</td>\n",
       "      <td>0.646919</td>\n",
       "      <td>0.526167</td>\n",
       "      <td>0.487295</td>\n",
       "      <td>0.492667</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>0.547928</td>\n",
       "      <td>0.594383</td>\n",
       "      <td>0.640838</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>0.182643</td>\n",
       "      <td>0.118877</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>0.547928</td>\n",
       "      <td>0.594383</td>\n",
       "      <td>0.640838</td>\n",
       "      <td>0.519596</td>\n",
       "      <td>0.480574</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.387938</td>\n",
       "      <td>0.537772</td>\n",
       "      <td>0.583161</td>\n",
       "      <td>0.628989</td>\n",
       "      <td>0.387938</td>\n",
       "      <td>0.179257</td>\n",
       "      <td>0.116632</td>\n",
       "      <td>0.062899</td>\n",
       "      <td>0.387938</td>\n",
       "      <td>0.537772</td>\n",
       "      <td>0.583161</td>\n",
       "      <td>0.628989</td>\n",
       "      <td>0.509643</td>\n",
       "      <td>0.471224</td>\n",
       "      <td>0.476819</td>\n",
       "      <td>0.364679</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0.560153</td>\n",
       "      <td>0.610683</td>\n",
       "      <td>0.364679</td>\n",
       "      <td>0.170460</td>\n",
       "      <td>0.112031</td>\n",
       "      <td>0.061068</td>\n",
       "      <td>0.364679</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0.560153</td>\n",
       "      <td>0.610683</td>\n",
       "      <td>0.487464</td>\n",
       "      <td>0.447995</td>\n",
       "      <td>0.453499</td>\n",
       "      <td>0.487464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.829700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.401166</td>\n",
       "      <td>0.555702</td>\n",
       "      <td>0.603160</td>\n",
       "      <td>0.652122</td>\n",
       "      <td>0.401166</td>\n",
       "      <td>0.185234</td>\n",
       "      <td>0.120632</td>\n",
       "      <td>0.065212</td>\n",
       "      <td>0.401166</td>\n",
       "      <td>0.555702</td>\n",
       "      <td>0.603160</td>\n",
       "      <td>0.652122</td>\n",
       "      <td>0.527511</td>\n",
       "      <td>0.487450</td>\n",
       "      <td>0.492721</td>\n",
       "      <td>0.402169</td>\n",
       "      <td>0.554950</td>\n",
       "      <td>0.599774</td>\n",
       "      <td>0.649614</td>\n",
       "      <td>0.402169</td>\n",
       "      <td>0.184983</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>0.064961</td>\n",
       "      <td>0.402169</td>\n",
       "      <td>0.554950</td>\n",
       "      <td>0.599774</td>\n",
       "      <td>0.649614</td>\n",
       "      <td>0.526402</td>\n",
       "      <td>0.486844</td>\n",
       "      <td>0.492206</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>0.548994</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.643471</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>0.182998</td>\n",
       "      <td>0.119140</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>0.548994</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.643471</td>\n",
       "      <td>0.520259</td>\n",
       "      <td>0.480653</td>\n",
       "      <td>0.486182</td>\n",
       "      <td>0.389067</td>\n",
       "      <td>0.538023</td>\n",
       "      <td>0.584916</td>\n",
       "      <td>0.634255</td>\n",
       "      <td>0.389067</td>\n",
       "      <td>0.179341</td>\n",
       "      <td>0.116983</td>\n",
       "      <td>0.063425</td>\n",
       "      <td>0.389067</td>\n",
       "      <td>0.538023</td>\n",
       "      <td>0.584916</td>\n",
       "      <td>0.634255</td>\n",
       "      <td>0.512085</td>\n",
       "      <td>0.472870</td>\n",
       "      <td>0.478425</td>\n",
       "      <td>0.369820</td>\n",
       "      <td>0.517146</td>\n",
       "      <td>0.563225</td>\n",
       "      <td>0.613378</td>\n",
       "      <td>0.369820</td>\n",
       "      <td>0.172382</td>\n",
       "      <td>0.112645</td>\n",
       "      <td>0.061338</td>\n",
       "      <td>0.369820</td>\n",
       "      <td>0.517146</td>\n",
       "      <td>0.563225</td>\n",
       "      <td>0.613378</td>\n",
       "      <td>0.491722</td>\n",
       "      <td>0.452716</td>\n",
       "      <td>0.458580</td>\n",
       "      <td>0.491722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.968000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.416212</td>\n",
       "      <td>0.565607</td>\n",
       "      <td>0.610244</td>\n",
       "      <td>0.659833</td>\n",
       "      <td>0.416212</td>\n",
       "      <td>0.188536</td>\n",
       "      <td>0.122049</td>\n",
       "      <td>0.065983</td>\n",
       "      <td>0.416212</td>\n",
       "      <td>0.565607</td>\n",
       "      <td>0.610244</td>\n",
       "      <td>0.659833</td>\n",
       "      <td>0.538639</td>\n",
       "      <td>0.499736</td>\n",
       "      <td>0.504924</td>\n",
       "      <td>0.414457</td>\n",
       "      <td>0.562347</td>\n",
       "      <td>0.607924</td>\n",
       "      <td>0.657514</td>\n",
       "      <td>0.414457</td>\n",
       "      <td>0.187449</td>\n",
       "      <td>0.121585</td>\n",
       "      <td>0.065751</td>\n",
       "      <td>0.414457</td>\n",
       "      <td>0.562347</td>\n",
       "      <td>0.607924</td>\n",
       "      <td>0.657514</td>\n",
       "      <td>0.536384</td>\n",
       "      <td>0.497516</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.408501</td>\n",
       "      <td>0.559401</td>\n",
       "      <td>0.602721</td>\n",
       "      <td>0.651871</td>\n",
       "      <td>0.408501</td>\n",
       "      <td>0.186467</td>\n",
       "      <td>0.120544</td>\n",
       "      <td>0.065187</td>\n",
       "      <td>0.408501</td>\n",
       "      <td>0.559401</td>\n",
       "      <td>0.602721</td>\n",
       "      <td>0.651871</td>\n",
       "      <td>0.531091</td>\n",
       "      <td>0.492288</td>\n",
       "      <td>0.497704</td>\n",
       "      <td>0.400539</td>\n",
       "      <td>0.549370</td>\n",
       "      <td>0.594257</td>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.400539</td>\n",
       "      <td>0.183123</td>\n",
       "      <td>0.118851</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>0.400539</td>\n",
       "      <td>0.549370</td>\n",
       "      <td>0.594257</td>\n",
       "      <td>0.642468</td>\n",
       "      <td>0.522478</td>\n",
       "      <td>0.483946</td>\n",
       "      <td>0.489480</td>\n",
       "      <td>0.381606</td>\n",
       "      <td>0.530625</td>\n",
       "      <td>0.573381</td>\n",
       "      <td>0.622281</td>\n",
       "      <td>0.381606</td>\n",
       "      <td>0.176875</td>\n",
       "      <td>0.114676</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.381606</td>\n",
       "      <td>0.530625</td>\n",
       "      <td>0.573381</td>\n",
       "      <td>0.622281</td>\n",
       "      <td>0.502864</td>\n",
       "      <td>0.464515</td>\n",
       "      <td>0.470280</td>\n",
       "      <td>0.502864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.414958</td>\n",
       "      <td>0.567739</td>\n",
       "      <td>0.612752</td>\n",
       "      <td>0.660523</td>\n",
       "      <td>0.414958</td>\n",
       "      <td>0.189246</td>\n",
       "      <td>0.122550</td>\n",
       "      <td>0.066052</td>\n",
       "      <td>0.414958</td>\n",
       "      <td>0.567739</td>\n",
       "      <td>0.612752</td>\n",
       "      <td>0.660523</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.499722</td>\n",
       "      <td>0.504997</td>\n",
       "      <td>0.414833</td>\n",
       "      <td>0.564040</td>\n",
       "      <td>0.609554</td>\n",
       "      <td>0.658705</td>\n",
       "      <td>0.414833</td>\n",
       "      <td>0.188013</td>\n",
       "      <td>0.121911</td>\n",
       "      <td>0.065870</td>\n",
       "      <td>0.414833</td>\n",
       "      <td>0.564040</td>\n",
       "      <td>0.609554</td>\n",
       "      <td>0.658705</td>\n",
       "      <td>0.537331</td>\n",
       "      <td>0.498372</td>\n",
       "      <td>0.503723</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.561344</td>\n",
       "      <td>0.605040</td>\n",
       "      <td>0.655382</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.187115</td>\n",
       "      <td>0.121008</td>\n",
       "      <td>0.065538</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.561344</td>\n",
       "      <td>0.605040</td>\n",
       "      <td>0.655382</td>\n",
       "      <td>0.534153</td>\n",
       "      <td>0.495256</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>0.399975</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.594947</td>\n",
       "      <td>0.644348</td>\n",
       "      <td>0.399975</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.118989</td>\n",
       "      <td>0.064435</td>\n",
       "      <td>0.399975</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.594947</td>\n",
       "      <td>0.644348</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.484046</td>\n",
       "      <td>0.489624</td>\n",
       "      <td>0.381355</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.574071</td>\n",
       "      <td>0.623284</td>\n",
       "      <td>0.381355</td>\n",
       "      <td>0.176269</td>\n",
       "      <td>0.114814</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.381355</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.574071</td>\n",
       "      <td>0.623284</td>\n",
       "      <td>0.502908</td>\n",
       "      <td>0.464277</td>\n",
       "      <td>0.470081</td>\n",
       "      <td>0.502908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.348900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.419848</td>\n",
       "      <td>0.570309</td>\n",
       "      <td>0.614068</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.419848</td>\n",
       "      <td>0.190103</td>\n",
       "      <td>0.122814</td>\n",
       "      <td>0.066259</td>\n",
       "      <td>0.419848</td>\n",
       "      <td>0.570309</td>\n",
       "      <td>0.614068</td>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.542104</td>\n",
       "      <td>0.503388</td>\n",
       "      <td>0.508618</td>\n",
       "      <td>0.417153</td>\n",
       "      <td>0.567174</td>\n",
       "      <td>0.612689</td>\n",
       "      <td>0.660523</td>\n",
       "      <td>0.417153</td>\n",
       "      <td>0.189058</td>\n",
       "      <td>0.122538</td>\n",
       "      <td>0.066052</td>\n",
       "      <td>0.417153</td>\n",
       "      <td>0.567174</td>\n",
       "      <td>0.612689</td>\n",
       "      <td>0.660523</td>\n",
       "      <td>0.539691</td>\n",
       "      <td>0.500849</td>\n",
       "      <td>0.506150</td>\n",
       "      <td>0.412827</td>\n",
       "      <td>0.563914</td>\n",
       "      <td>0.609115</td>\n",
       "      <td>0.656511</td>\n",
       "      <td>0.412827</td>\n",
       "      <td>0.187971</td>\n",
       "      <td>0.121823</td>\n",
       "      <td>0.065651</td>\n",
       "      <td>0.412827</td>\n",
       "      <td>0.563914</td>\n",
       "      <td>0.609115</td>\n",
       "      <td>0.656511</td>\n",
       "      <td>0.535814</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>0.502342</td>\n",
       "      <td>0.401730</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.598897</td>\n",
       "      <td>0.648549</td>\n",
       "      <td>0.401730</td>\n",
       "      <td>0.184461</td>\n",
       "      <td>0.119779</td>\n",
       "      <td>0.064855</td>\n",
       "      <td>0.401730</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.598897</td>\n",
       "      <td>0.648549</td>\n",
       "      <td>0.526100</td>\n",
       "      <td>0.486762</td>\n",
       "      <td>0.492199</td>\n",
       "      <td>0.385995</td>\n",
       "      <td>0.535076</td>\n",
       "      <td>0.579337</td>\n",
       "      <td>0.629553</td>\n",
       "      <td>0.385995</td>\n",
       "      <td>0.178359</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>0.385995</td>\n",
       "      <td>0.535076</td>\n",
       "      <td>0.579337</td>\n",
       "      <td>0.629553</td>\n",
       "      <td>0.508493</td>\n",
       "      <td>0.469663</td>\n",
       "      <td>0.475350</td>\n",
       "      <td>0.508493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.796900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.420162</td>\n",
       "      <td>0.569557</td>\n",
       "      <td>0.614507</td>\n",
       "      <td>0.662717</td>\n",
       "      <td>0.420162</td>\n",
       "      <td>0.189852</td>\n",
       "      <td>0.122901</td>\n",
       "      <td>0.066272</td>\n",
       "      <td>0.420162</td>\n",
       "      <td>0.569557</td>\n",
       "      <td>0.614507</td>\n",
       "      <td>0.662717</td>\n",
       "      <td>0.542292</td>\n",
       "      <td>0.503598</td>\n",
       "      <td>0.508895</td>\n",
       "      <td>0.417591</td>\n",
       "      <td>0.567363</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.661087</td>\n",
       "      <td>0.417591</td>\n",
       "      <td>0.189121</td>\n",
       "      <td>0.122701</td>\n",
       "      <td>0.066109</td>\n",
       "      <td>0.417591</td>\n",
       "      <td>0.567363</td>\n",
       "      <td>0.613504</td>\n",
       "      <td>0.661087</td>\n",
       "      <td>0.540208</td>\n",
       "      <td>0.501358</td>\n",
       "      <td>0.506677</td>\n",
       "      <td>0.412513</td>\n",
       "      <td>0.562974</td>\n",
       "      <td>0.608363</td>\n",
       "      <td>0.656322</td>\n",
       "      <td>0.412513</td>\n",
       "      <td>0.187658</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.412513</td>\n",
       "      <td>0.562974</td>\n",
       "      <td>0.608363</td>\n",
       "      <td>0.656322</td>\n",
       "      <td>0.535423</td>\n",
       "      <td>0.496574</td>\n",
       "      <td>0.501986</td>\n",
       "      <td>0.403862</td>\n",
       "      <td>0.553758</td>\n",
       "      <td>0.598897</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.403862</td>\n",
       "      <td>0.184586</td>\n",
       "      <td>0.119779</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>0.403862</td>\n",
       "      <td>0.553758</td>\n",
       "      <td>0.598897</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.526847</td>\n",
       "      <td>0.487761</td>\n",
       "      <td>0.493208</td>\n",
       "      <td>0.387562</td>\n",
       "      <td>0.534637</td>\n",
       "      <td>0.578584</td>\n",
       "      <td>0.629490</td>\n",
       "      <td>0.387562</td>\n",
       "      <td>0.178212</td>\n",
       "      <td>0.115717</td>\n",
       "      <td>0.062949</td>\n",
       "      <td>0.387562</td>\n",
       "      <td>0.534637</td>\n",
       "      <td>0.578584</td>\n",
       "      <td>0.629490</td>\n",
       "      <td>0.508979</td>\n",
       "      <td>0.470347</td>\n",
       "      <td>0.476051</td>\n",
       "      <td>0.508979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    " \n",
    "# save the best model\n",
    "trainer.save_model()\n",
    " \n",
    "# # push model to hub\n",
    "# trainer.model.push_to_hub(\"bge-base-financial-matryoshka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4aad25",
   "metadata": {},
   "source": [
    "5. Evaluate fine-tuned model against baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3846cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_accuracy@1 0.4199109773681901\n",
      "dim_768_cosine_accuracy@3 0.5694313836123127\n",
      "dim_768_cosine_accuracy@5 0.6146323114538274\n",
      "dim_768_cosine_accuracy@10 0.6627797630242618\n",
      "dim_768_cosine_precision@1 0.4199109773681901\n",
      "dim_768_cosine_precision@3 0.18981046120410425\n",
      "dim_768_cosine_precision@5 0.12292646229076545\n",
      "dim_768_cosine_precision@10 0.06627797630242617\n",
      "dim_768_cosine_recall@1 0.4199109773681901\n",
      "dim_768_cosine_recall@3 0.5694313836123127\n",
      "dim_768_cosine_recall@5 0.6146323114538274\n",
      "dim_768_cosine_recall@10 0.6627797630242618\n",
      "dim_768_cosine_ndcg@10 0.5422040066911552\n",
      "dim_768_cosine_mrr@10 0.5034606229593954\n",
      "dim_768_cosine_map@100 0.5087533694160415\n",
      "dim_512_cosine_accuracy@1 0.418218293523917\n",
      "dim_512_cosine_accuracy@3 0.5677386997680396\n",
      "dim_512_cosine_accuracy@5 0.6136292395461099\n",
      "dim_512_cosine_accuracy@10 0.6612751551626858\n",
      "dim_512_cosine_precision@1 0.418218293523917\n",
      "dim_512_cosine_precision@3 0.18924623325601322\n",
      "dim_512_cosine_precision@5 0.12272584790922199\n",
      "dim_512_cosine_precision@10 0.06612751551626855\n",
      "dim_512_cosine_recall@1 0.418218293523917\n",
      "dim_512_cosine_recall@3 0.5677386997680396\n",
      "dim_512_cosine_recall@5 0.6136292395461099\n",
      "dim_512_cosine_recall@10 0.6612751551626858\n",
      "dim_512_cosine_ndcg@10 0.5405224586223994\n",
      "dim_512_cosine_mrr@10 0.5017248259301992\n",
      "dim_512_cosine_map@100 0.5070274516632539\n",
      "dim_256_cosine_accuracy@1 0.4120117860949157\n",
      "dim_256_cosine_accuracy@3 0.5629114162121497\n",
      "dim_256_cosine_accuracy@5 0.6084884960190584\n",
      "dim_256_cosine_accuracy@10 0.6563224876183311\n",
      "dim_256_cosine_precision@1 0.4120117860949157\n",
      "dim_256_cosine_precision@3 0.18763713873738325\n",
      "dim_256_cosine_precision@5 0.12169769920381167\n",
      "dim_256_cosine_precision@10 0.06563224876183311\n",
      "dim_256_cosine_recall@1 0.4120117860949157\n",
      "dim_256_cosine_recall@3 0.5629114162121497\n",
      "dim_256_cosine_recall@5 0.6084884960190584\n",
      "dim_256_cosine_recall@10 0.6563224876183311\n",
      "dim_256_cosine_ndcg@10 0.5352429826823204\n",
      "dim_256_cosine_mrr@10 0.49632948324879345\n",
      "dim_256_cosine_map@100 0.5017368608996177\n",
      "dim_128_cosine_accuracy@1 0.40317221490815625\n",
      "dim_128_cosine_accuracy@3 0.5536330010657639\n",
      "dim_128_cosine_accuracy@5 0.5995235408438342\n",
      "dim_128_cosine_accuracy@10 0.648485988339289\n",
      "dim_128_cosine_precision@1 0.40317221490815625\n",
      "dim_128_cosine_precision@3 0.18454433368858797\n",
      "dim_128_cosine_precision@5 0.11990470816876685\n",
      "dim_128_cosine_precision@10 0.06484859883392892\n",
      "dim_128_cosine_recall@1 0.40317221490815625\n",
      "dim_128_cosine_recall@3 0.5536330010657639\n",
      "dim_128_cosine_recall@5 0.5995235408438342\n",
      "dim_128_cosine_recall@10 0.648485988339289\n",
      "dim_128_cosine_ndcg@10 0.5265200472016692\n",
      "dim_128_cosine_mrr@10 0.48736176664048964\n",
      "dim_128_cosine_map@100 0.49282909186404317\n",
      "dim_64_cosine_accuracy@1 0.3871857563789104\n",
      "dim_64_cosine_accuracy@3 0.5347000188075983\n",
      "dim_64_cosine_accuracy@5 0.5785844147702338\n",
      "dim_64_cosine_accuracy@10 0.6298664660522851\n",
      "dim_64_cosine_precision@1 0.3871857563789104\n",
      "dim_64_cosine_precision@3 0.17823333960253276\n",
      "dim_64_cosine_precision@5 0.11571688295404675\n",
      "dim_64_cosine_precision@10 0.0629866466052285\n",
      "dim_64_cosine_recall@1 0.3871857563789104\n",
      "dim_64_cosine_recall@3 0.5347000188075983\n",
      "dim_64_cosine_recall@5 0.5785844147702338\n",
      "dim_64_cosine_recall@10 0.6298664660522851\n",
      "dim_64_cosine_ndcg@10 0.5089569549232311\n",
      "dim_64_cosine_mrr@10 0.4702066497298719\n",
      "dim_64_cosine_map@100 0.47587807760201245\n",
      "sequential_score 0.5089569549232311\n",
      "=======================\n",
      "dim_768_cosine_ndcg@10: 0.5422040066911552\n",
      "dim_512_cosine_ndcg@10: 0.5405224586223994\n",
      "dim_256_cosine_ndcg@10: 0.5352429826823204\n",
      "dim_128_cosine_ndcg@10: 0.5265200472016692\n",
      "dim_64_cosine_ndcg@10: 0.5089569549232311\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    " \n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    " \n",
    "# # COMMENT IN for full results\n",
    "for k,v in results.items():\n",
    "    print(k, v)\n",
    "    \n",
    "print(\"=======================\")\n",
    " \n",
    "# Print the main score\n",
    "for dim in matryoshka_dimensions:\n",
    "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "    print(f\"{key}: {results[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
