{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8fb99b",
   "metadata": {},
   "source": [
    "1. Create & Prepare embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a1801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\HocTap\\ChatBot\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1973\n",
      "After: 1579\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    " \n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset('csv', data_files='../dataset/QA_data.csv', split=\"train\")\n",
    "\n",
    "\n",
    "# Shuffle trước để chọn ngẫu nhiên\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Lấy 1/100 số dòng\n",
    "dataset = dataset.select(range(len(dataset) // 100))\n",
    "\n",
    "\n",
    "print(\"Before:\", len(dataset))\n",
    "dataset = dataset.filter(lambda x: x[\"Answer\"])\n",
    "print(\"After:\", len(dataset))\n",
    "# rename columns\n",
    "dataset = dataset.rename_column(\"Question\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"Answer\", \"positive\")\n",
    " \n",
    "# Add an id column to the dataset\n",
    "dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
    " \n",
    "# split dataset into a 10% test set\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    " \n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_pandas().to_json(\"train_dataset.json\", orient=\"records\", lines=True, force_ascii=False)\n",
    "dataset[\"test\"].to_pandas().to_json(\"test_dataset.json\", orient=\"records\", lines=True, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efac7b",
   "metadata": {},
   "source": [
    "2. Create baseline and evaluate pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785a78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 158 examples [00:00, 12730.52 examples/s]\n",
      "Generating train split: 1421 examples [00:00, 156289.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    " \n",
    "# load test dataset\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    " \n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")  # Our queries (qid => question)\n",
    " \n",
    "# Create a mapping of relevant document (1 in our case) for each query\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for q_id in queries:\n",
    "    relevant_docs[q_id] = [q_id]\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ace00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "model_id = \"hiieu/halong_embedding\"  # Hugging Face model ID\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64] # Important: large to small\n",
    " \n",
    "# Load a model\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    " \n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c48386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# results = evaluator(model)\n",
    "# for k,v in results.items():\n",
    "#     print(k, v)\n",
    "\n",
    "# print(\"=======================\")\n",
    "# for dim in matryoshka_dimensions:\n",
    "#     key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "#     print\n",
    "#     print(f\"{key}: {results[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1f694",
   "metadata": {},
   "source": [
    "3. Define loss function with Matryoshka Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a9ee62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['anchor', 'Context', 'positive', 'Answer_Start', 'Answer_End', 'id'],\n",
       "    num_rows: 1421\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerModelCardData, SentenceTransformer\n",
    " \n",
    "# Hugging Face model ID: https://huggingface.co/BAAI/bge-base-en-v1.5\n",
    "model_id = \"hiieu/halong_embedding\"\n",
    " \n",
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    model_id,\n",
    "    model_kwargs={\"attn_implementation\": \"sdpa\"},\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"BGE base Financial Matryoshka\",\n",
    "    ),\n",
    ")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96822aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'Làm cách nào để ngăn ngừa chứng loạn sản thận?',\n",
       " 'Context': 'Thật không may, chứng loạn sản thận không thể ngăn ngừa được vì đây là một tình trạng bẩm sinh xảy ra trong quá trình phát triển của thai nhi. Tuy nhiên, việc phát hiện và điều trị sớm có thể giúp kiểm soát tình trạng và ngăn ngừa các biến chứng.',\n",
       " 'positive': 'Thật không may, chứng loạn sản thận không thể ngăn ngừa được vì đây là một tình trạng bẩm sinh xảy ra trong quá trình phát triển của thai nhi. Tuy nhiên, việc phát hiện và điều trị sớm có thể giúp kiểm soát tình trạng và ngăn ngừa các biến chứng.',\n",
       " 'Answer_Start': 0,\n",
       " 'Answer_End': 246,\n",
       " 'id': 76}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04face0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    " \n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78abdfb8",
   "metadata": {},
   "source": [
    "4. Fine-tune embedding model with SentenceTransformersTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c225058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    " \n",
    "# load train dataset again\n",
    " \n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"medical_embedding_vietnamese\", # output directory and hugging face model ID\n",
    "    num_train_epochs=1,                         # number of epochs\n",
    "    per_device_train_batch_size=16,             # train batch size\n",
    "    gradient_accumulation_steps=8,             # for a global batch size of 512\n",
    "    per_device_eval_batch_size=8,    \n",
    "    #gradient_checkpointing=True,\n",
    "    warmup_ratio=0.1,                           # warmup ratio\n",
    "    learning_rate=2e-5,                         # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                 # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
    "    # tf32=True,                                  # use tf32 precision\n",
    "    bf16=True,                                  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",                      # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",  \n",
    "    # save_steps = 500,\n",
    "    logging_steps=10,                           # log every 10 steps\n",
    "    save_total_limit=3,                         # save only the last 3 models\n",
    "    load_best_model_at_end=True,                # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    "    report_to = \"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c448529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    " \n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model, # bg-base-en-v1\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"anchor\", \"positive\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a3d8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 02:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 768 Cosine Accuracy@1</th>\n",
       "      <th>Dim 768 Cosine Accuracy@3</th>\n",
       "      <th>Dim 768 Cosine Accuracy@5</th>\n",
       "      <th>Dim 768 Cosine Accuracy@10</th>\n",
       "      <th>Dim 768 Cosine Precision@1</th>\n",
       "      <th>Dim 768 Cosine Precision@3</th>\n",
       "      <th>Dim 768 Cosine Precision@5</th>\n",
       "      <th>Dim 768 Cosine Precision@10</th>\n",
       "      <th>Dim 768 Cosine Recall@1</th>\n",
       "      <th>Dim 768 Cosine Recall@3</th>\n",
       "      <th>Dim 768 Cosine Recall@5</th>\n",
       "      <th>Dim 768 Cosine Recall@10</th>\n",
       "      <th>Dim 768 Cosine Ndcg@10</th>\n",
       "      <th>Dim 768 Cosine Mrr@10</th>\n",
       "      <th>Dim 768 Cosine Map@100</th>\n",
       "      <th>Dim 512 Cosine Accuracy@1</th>\n",
       "      <th>Dim 512 Cosine Accuracy@3</th>\n",
       "      <th>Dim 512 Cosine Accuracy@5</th>\n",
       "      <th>Dim 512 Cosine Accuracy@10</th>\n",
       "      <th>Dim 512 Cosine Precision@1</th>\n",
       "      <th>Dim 512 Cosine Precision@3</th>\n",
       "      <th>Dim 512 Cosine Precision@5</th>\n",
       "      <th>Dim 512 Cosine Precision@10</th>\n",
       "      <th>Dim 512 Cosine Recall@1</th>\n",
       "      <th>Dim 512 Cosine Recall@3</th>\n",
       "      <th>Dim 512 Cosine Recall@5</th>\n",
       "      <th>Dim 512 Cosine Recall@10</th>\n",
       "      <th>Dim 512 Cosine Ndcg@10</th>\n",
       "      <th>Dim 512 Cosine Mrr@10</th>\n",
       "      <th>Dim 512 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Dim 128 Cosine Accuracy@1</th>\n",
       "      <th>Dim 128 Cosine Accuracy@3</th>\n",
       "      <th>Dim 128 Cosine Accuracy@5</th>\n",
       "      <th>Dim 128 Cosine Accuracy@10</th>\n",
       "      <th>Dim 128 Cosine Precision@1</th>\n",
       "      <th>Dim 128 Cosine Precision@3</th>\n",
       "      <th>Dim 128 Cosine Precision@5</th>\n",
       "      <th>Dim 128 Cosine Precision@10</th>\n",
       "      <th>Dim 128 Cosine Recall@1</th>\n",
       "      <th>Dim 128 Cosine Recall@3</th>\n",
       "      <th>Dim 128 Cosine Recall@5</th>\n",
       "      <th>Dim 128 Cosine Recall@10</th>\n",
       "      <th>Dim 128 Cosine Ndcg@10</th>\n",
       "      <th>Dim 128 Cosine Mrr@10</th>\n",
       "      <th>Dim 128 Cosine Map@100</th>\n",
       "      <th>Dim 64 Cosine Accuracy@1</th>\n",
       "      <th>Dim 64 Cosine Accuracy@3</th>\n",
       "      <th>Dim 64 Cosine Accuracy@5</th>\n",
       "      <th>Dim 64 Cosine Accuracy@10</th>\n",
       "      <th>Dim 64 Cosine Precision@1</th>\n",
       "      <th>Dim 64 Cosine Precision@3</th>\n",
       "      <th>Dim 64 Cosine Precision@5</th>\n",
       "      <th>Dim 64 Cosine Precision@10</th>\n",
       "      <th>Dim 64 Cosine Recall@1</th>\n",
       "      <th>Dim 64 Cosine Recall@3</th>\n",
       "      <th>Dim 64 Cosine Recall@5</th>\n",
       "      <th>Dim 64 Cosine Recall@10</th>\n",
       "      <th>Dim 64 Cosine Ndcg@10</th>\n",
       "      <th>Dim 64 Cosine Mrr@10</th>\n",
       "      <th>Dim 64 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.099100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.244726</td>\n",
       "      <td>0.153165</td>\n",
       "      <td>0.079114</td>\n",
       "      <td>0.689873</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.791139</td>\n",
       "      <td>0.735996</td>\n",
       "      <td>0.718688</td>\n",
       "      <td>0.723143</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.753165</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.242616</td>\n",
       "      <td>0.150633</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.753165</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.736524</td>\n",
       "      <td>0.721534</td>\n",
       "      <td>0.726238</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.242616</td>\n",
       "      <td>0.146835</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.717246</td>\n",
       "      <td>0.699920</td>\n",
       "      <td>0.704983</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.242616</td>\n",
       "      <td>0.148101</td>\n",
       "      <td>0.076582</td>\n",
       "      <td>0.620253</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.695815</td>\n",
       "      <td>0.673011</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.563291</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.715190</td>\n",
       "      <td>0.563291</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.136709</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.563291</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.715190</td>\n",
       "      <td>0.637231</td>\n",
       "      <td>0.612508</td>\n",
       "      <td>0.618377</td>\n",
       "      <td>0.637231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    " \n",
    "# save the best model\n",
    "trainer.save_model()\n",
    " \n",
    "# # push model to hub\n",
    "# trainer.model.push_to_hub(\"bge-base-financial-matryoshka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4aad25",
   "metadata": {},
   "source": [
    "5. Evaluate fine-tuned model against baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3846cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    " \n",
    "# fine_tuned_model = SentenceTransformer(\n",
    "#     args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )\n",
    "# # Evaluate the model\n",
    "# results = evaluator(fine_tuned_model)\n",
    " \n",
    "# # # COMMENT IN for full results\n",
    "# for k,v in results.items():\n",
    "#     print(k, v)\n",
    "    \n",
    "# print(\"=======================\")\n",
    " \n",
    "# # Print the main score\n",
    "# for dim in matryoshka_dimensions:\n",
    "#     key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "#     print(f\"{key}: {results[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
